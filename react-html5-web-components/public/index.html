<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document Sample</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <style>
    label {
      display: inline-block;
      width: 100px;
    }

    input[type="text"] {
      width: 300px;
      height: 30px;
      border-radius: 10px 10px;
      border: 1px solid #ac9d9d;
      padding: 10px 10px;
      margin: 10px 10px;
    }

    .hide-element {
      display: none;
    }

    .holster {
      display: flex;
      align-items: center;
      justify-content: space-between;
      flex-flow: column nowrap;
      font-family: monospace;
    }

    .container {
      display: flex;
      overflow: auto;
      outline: 1px dashed lightgray;
      flex: none;
    }

    .container.x {
      width: 100%;
      height: 128px;
      flex-flow: row nowrap;
    }

    .x.proximity-scroll-snapping {
      scroll-snap-type: x proximity;
    }

    .x.container>div {
      line-height: 128px;
      font-size: 64px;
      width: 100%;
      height: 128px;
    }

    /* coloration */
    .container>div:nth-child(even) {
      background-color: #87EA87;
    }

    .container>div:nth-child(odd) {
      background-color: #87CCEA;
    }

    .container>div {
      text-align: center;
      scroll-snap-align: center;
      flex: none;
    }
  </style>
</head>

<body id=html>
  <div class="hoister">
    <div class="container x proximity-scroll-snapping" dir="rtl">
      <div>X Prox. RTL</div>
      <div>2</div>
      <div>3</div>
      <div>4</div>
      <div>5</div>
    </div>
  </div>
  <main id="app"></main>
  <div>
    <h1>camera Example</h1>
    <p>By clicking on <button id=start-camera-button>Start Camera</button> button you will be prompted to authorize
      Camera permission. Once approved you will see the
      camera output!
    </p>
    <video class=hide-element id=video-output width=300 height=400 controls></video>
    <canvas id="video-canvas" style="left:0px;border:5px solid red" height=400 width=300></canvas>
  </div>
  <div>
    <h1>Bluetooth test</h1>
    <button id=start-blue-tooth>Start bluetooth scan!</button>
  </div>
  <div id="demo-speech-test">
    <h1>Speech Example <button class=btn-start-speech data-result=to><i style="font-size:24px" class="fa">&#xf130;</i></button></h1>
    <hr />
    <div>
      <label>To</label>
      <input type=text id=to>
      <button class=btn-start-speech data-result=to><i style="font-size:24px" class="fa">&#xf130;</i></button>
    </div>
    <div>
      <label>From</label>
      <input type=text id=from>
      <button class=btn-start-speech data-result=from><i style="font-size:24px" class="fa">&#xf130;</i></button>
    </div>

    <div id=station-name>
    </div>
    <script>

      function startCamera() {
        const startCameraButton = document.getElementById("start-camera-button")
        startCameraButton.addEventListener("click", startCameraHandler)
        const videoOutput = document.getElementById("video-output")
        async function startCameraHandler(_) {
          videoOutput.srcObject = await navigator.mediaDevices.getUserMedia({ video: true })
          videoOutput.classList.toggle("hide-element")
          videoOutput.addEventListener("loadeddata", () => {
            mapStreamSourceToCanvas(videoOutput)
          }, false)

        }

        function mapStreamSourceToCanvas(video) {
          const canvasEl = document.getElementById("video-canvas")
          const context = canvasEl.getContext("2d")

          context.drawImage(video, 0, 0, 300, 400)
          findColor(context)
          setTimeout(() => mapStreamSourceToCanvas(video), 0)
        }

        function findColor(context) {
          let frame = context.getImageData(0, 0, 300, 400)
          let data = frame.data.length / 4
          for (let i = 0; i < data; i++) {
            let r = frame.data[i * 4 + 0]
            let g = frame.data[i * 4 + 1]
            let b = frame.data[i * 4 + 2]

            if (b <= 10 || g <= 100) frame.data[i * 4 + 3] = 0
          }
          context.putImageData(frame, 0, 0)
        }
      }

      startCamera()


      function bootstrapSpeech() {

        const stations = ["Liverpool Street", "Ilford", "Bank","Line Status"]
        const grammar = `#JSGF V1.0; stations; public <stations> =${stations.join(" | ")};`
        const recognition = new webkitSpeechRecognition()
        const speechList = new webkitSpeechGrammarList()
        speechList.addFromString(grammar, 1)

        recognition.grammar = speechList
        recognition.lang = 'en-US'
        recognition.interimResults = false
        recognition.maxAlternatives = 1

        const startSpeechButtons = document.querySelectorAll(".btn-start-speech")
        startSpeechButtons.forEach(btn => btn.addEventListener("click", speechStartHandler))

        let result = null
        function speechStartHandler(event) {
          const destId = event.target.parentElement.getAttribute("data-result") ||
            event.target.getAttribute("data-result")

          result = document.getElementById(destId)

          alert("Starting new session for speech")
          result.value = "waiting...."
          recognition.start()
        }

        recognition.onresult = event => {
          const match = event.results[0][0].transcript
          if (String(match).toLowerCase() === "line status") window.location.href="https://tfl.gov.uk/tube-dlr-overground/status/"
          result.value = match
        };
      }

      bootstrapSpeech()

      function bluetoothExample() {

        document.getElementById("start-blue-tooth")
          .addEventListener("click", bluetoothHandler)
        function bluetoothHandler() {
          navigator.bluetooth.requestDevice({ acceptAllDevices: true })
            .then(v => console.log(v))
            .catch(e => console.log(e))
        }
      }

      bluetoothExample()



    </script>
</body>

</html>